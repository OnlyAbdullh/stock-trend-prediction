{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-27T21:09:07.175811500Z",
     "start_time": "2026-01-27T21:09:03.708041800Z"
    }
   },
   "source": [
    "import random\n",
    "import sys, os\n",
    "PROJECT_ROOT = r\"D:\\Stock_trend_project\"\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import List, Tuple\n",
    "\n",
    "from src.data.stock_dataset import StockDataset\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "def build_samples(window_size = 60):\n",
    "    print(\"Loading CSV...\")\n",
    "    df = pd.read_csv('D:\\Stock_trend_project\\data\\processed\\\\new_stocks_features2.csv')\n",
    "\n",
    "    ticker_data = {}\n",
    "    samples = []\n",
    "    horizon = 30\n",
    "    FEATURE_COLS = [\n",
    "    # Price Features (3)\n",
    "    'daily_return',\n",
    "    'high_low_ratio',\n",
    "\n",
    "    # MA-Based (4)\n",
    "    'price_to_MA5',\n",
    "    'price_to_MA20',\n",
    "    'price_to_MA60',\n",
    "    'MA_60_slope',\n",
    "\n",
    "    # Volatility (3)\n",
    "    'volatility_20',\n",
    "    'RSI_14',\n",
    "    'parkinson_volatility',\n",
    "\n",
    "    # Critical Features (4)\n",
    "    'recent_high_20',\n",
    "    'distance_from_high',\n",
    "    'low_to_close_ratio',\n",
    "    'price_position_20',\n",
    "    'max_drawdown_20',\n",
    "    'downside_deviation_10',\n",
    "\n",
    "    # Temporal (3)\n",
    "    'month_sin',\n",
    "    'month_cos',\n",
    "    'is_up_day',\n",
    "\n",
    "    # Volume Price Index (3) - Highest MI!\n",
    "    'PVT_cumsum',           # MI = 0.0426 ⭐️⭐️⭐️\n",
    "    'MOBV',                 # MI = 0.0209 ⭐️⭐️\n",
    "\n",
    "    # Directional Movement (4)\n",
    "    'MTM',                  # MI = 0.0127 ⭐️\n",
    "\n",
    "    # OverBought & OverSold (1)\n",
    "    'ADTM',                 # MI = 0.0104\n",
    "\n",
    "    # Energy & Volatility (2)\n",
    "    'PSY',                  # MI = 0.0085\n",
    "    'VHF',                  # MI = 0.0088\n",
    "\n",
    "    # Stochastic (1)\n",
    "    'K',                    # MI = 0.0083\n",
    "\n",
    "    # Raw Features\n",
    "    ]\n",
    "    for ticker, group in tqdm(df.groupby('ticker'), desc=\"Processing tickers\"):\n",
    "        group = group.sort_values('date').reset_index(drop=True)\n",
    "        n = len(group)\n",
    "\n",
    "        if n < window_size + horizon:\n",
    "            continue\n",
    "\n",
    "        close = group['close'].values.astype(np.float32)\n",
    "        missing = group[\"missing_days\"].values.astype(np.int8)\n",
    "        bad = (missing > 0).astype(np.int32)\n",
    "        bad_cumsum = np.cumsum(bad)\n",
    "\n",
    "        def has_gap(a, b):\n",
    "            return bad_cumsum[b] - (bad_cumsum[a - 1] if a > 0 else 0) > 0\n",
    "\n",
    "        ticker_data[ticker] = group[FEATURE_COLS].values.astype(np.float32)\n",
    "\n",
    "        dates = group['date'].values\n",
    "        for i in range(window_size, n - horizon):\n",
    "            seq_start = i - window_size + 1\n",
    "            seq_end = i + horizon\n",
    "\n",
    "            if has_gap(seq_start, seq_end):\n",
    "                continue\n",
    "\n",
    "            label = 1 if close[i + horizon] > close[i] else 0\n",
    "\n",
    "            date = dates[i]\n",
    "            samples.append((ticker, i, label, date))\n",
    "    StockDataset.ticker_data = ticker_data\n",
    "    print(f\"✓ Processed {len(samples):,} samples from {len(ticker_data)} tickers\")\n",
    "    return samples\n",
    "\n",
    "\n",
    "def split_samples_time_based(\n",
    "        samples: List[Tuple[str, int, int, object]],\n",
    "        train_ratio: float = 0.7,\n",
    "        val_ratio: float = 0.15,\n",
    "):\n",
    "    samples_sorted = sorted(samples, key=lambda x: x[3])\n",
    "\n",
    "    n = len(samples_sorted)\n",
    "    n_train = int(n * train_ratio)\n",
    "    n_val = int(n * val_ratio)\n",
    "\n",
    "    train_samples = samples_sorted[:n_train]\n",
    "    val_samples = samples_sorted[n_train:n_train + n_val]\n",
    "    test_samples = samples_sorted[n_train + n_val:]\n",
    "    return train_samples, val_samples, test_samples"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T21:09:08.470067800Z",
     "start_time": "2026-01-27T21:09:07.176878700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PROJECT_ROOT = r\"D:\\Stock_trend_project\"\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "from typing import Dict, List, Optional\n",
    "from src.data.make_torch_datasets import build_samples, split_samples_time_based\n",
    "from src.data.stock_dataset import StockDataset\n",
    "from src.models.gru_model import GRUModel\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from src.configs.training_config import BASELINE, BIDIRECTIONAL_STRONG, DEEP_NETWORK, FAST_EXPERIMENTAL, FIRST_CONFIG\n",
    "\n",
    "CFG = DEEP_NETWORK\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def run_epoch(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    train: bool = True,\n",
    "    optimizer: Optional[torch.optim.Optimizer] = None,\n",
    ") -> Dict[str, float]:\n",
    "    if train:\n",
    "        model.train()\n",
    "        context = torch.enable_grad()\n",
    "    else:\n",
    "        model.eval()\n",
    "        context = torch.no_grad()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    running_total = 0\n",
    "\n",
    "    with context:\n",
    "        for X, y in loader:\n",
    "            X = X.to(device)          # (batch, seq_len, input_size)\n",
    "            y = y.to(device).float()  # (batch,)\n",
    "\n",
    "            logits = model(X)         # (batch,)\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "            if train:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * y.size(0)\n",
    "\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs >= 0.5).float()\n",
    "            running_correct += (preds == y).sum().item()\n",
    "            running_total += y.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / running_total\n",
    "    epoch_acc = running_correct / running_total\n",
    "\n",
    "    return {\"loss\": epoch_loss, \"acc\": epoch_acc}\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    num_epochs: int,\n",
    "    config: object,\n",
    "):\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "    history: Dict[str, List[float]] = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_acc\": [],\n",
    "    }\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_state_dict = None\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_metrics = run_epoch(\n",
    "            model=model,\n",
    "            loader=train_loader,\n",
    "            criterion=criterion,\n",
    "            train=True,\n",
    "            optimizer=optimizer,\n",
    "        )\n",
    "\n",
    "        val_metrics = run_epoch(\n",
    "            model=model,\n",
    "            loader=val_loader,\n",
    "            criterion=criterion,\n",
    "            train=False,\n",
    "            optimizer=None,\n",
    "        )\n",
    "\n",
    "        history[\"train_loss\"].append(train_metrics[\"loss\"])\n",
    "        history[\"train_acc\"].append(train_metrics[\"acc\"])\n",
    "        history[\"val_loss\"].append(val_metrics[\"loss\"])\n",
    "        history[\"val_acc\"].append(val_metrics[\"acc\"])\n",
    "\n",
    "        if val_metrics[\"loss\"] < best_val_loss:\n",
    "            best_val_loss = val_metrics[\"loss\"]\n",
    "            best_state_dict = model.state_dict()\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch:03d} | \"\n",
    "            f\"train_loss={train_metrics['loss']:.4f}  \"\n",
    "            f\"train_acc={train_metrics['acc']:.4f}  \"\n",
    "            f\"val_loss={val_metrics['loss']:.4f}  \"\n",
    "            f\"val_acc={val_metrics['acc']:.4f}\"\n",
    "        )\n",
    "\n",
    "    if best_state_dict is not None:\n",
    "        model.load_state_dict(best_state_dict)\n",
    "\n",
    "    return model, history\n",
    "\n"
   ],
   "id": "78f41a9c1c384ad5",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T21:10:31.904297700Z",
     "start_time": "2026-01-27T21:09:08.545099800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "    torch.manual_seed(42)\n",
    "\n",
    "    samples = build_samples(window_size=CFG.window_size)\n",
    "    train_s, val_s, test_s = split_samples_time_based(samples)\n",
    "\n",
    "    train_ds = StockDataset(train_s, window_size=CFG.window_size, horizon=30)\n",
    "    val_ds = StockDataset(val_s, window_size=CFG.window_size, horizon=30)\n",
    "    test_ds = StockDataset(test_s, window_size=CFG.window_size, horizon=30)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=CFG.batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=CFG.batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_ds, batch_size=CFG.batch_size, shuffle=False)\n"
   ],
   "id": "dd7e7e709dcc605",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing tickers: 100%|██████████| 4925/4925 [00:17<00:00, 284.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Processed 11,070,798 samples from 4923 tickers\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T22:31:49.489220Z",
     "start_time": "2026-01-27T21:10:31.916189800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "    X_batch, y_batch = next(iter(train_loader))\n",
    "    input_size = X_batch.shape[2]\n",
    "\n",
    "    model = GRUModel(\n",
    "        input_size=input_size,\n",
    "        hidden_size=CFG.hidden_size,\n",
    "        num_layers=CFG.num_layers,\n",
    "        dropout=CFG.dropout,\n",
    "        bidirectional=CFG.bidirectional,\n",
    "    )\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    model, history = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        num_epochs=4,\n",
    "        config=CFG,\n",
    "    )\n",
    "\n",
    "    print(\"Training finished.\")"
   ],
   "id": "9555832ab69d3e0e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 001 | train_loss=0.6799  train_acc=0.5708  val_loss=0.7158  val_acc=0.4431\n",
      "Epoch 002 | train_loss=0.6760  train_acc=0.5741  val_loss=0.7128  val_acc=0.4438\n",
      "Epoch 003 | train_loss=0.6748  train_acc=0.5756  val_loss=0.7219  val_acc=0.4348\n",
      "Epoch 004 | train_loss=0.6736  train_acc=0.5777  val_loss=0.7243  val_acc=0.4448\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d6d129974bb65eaa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ac5d142d74a8bcbb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
